{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Documentation","text":""},{"location":"color/","title":"Colors","text":""},{"location":"color/#bash-colors","title":"Bash Colors","text":"<p>Script to display all terminal colors</p> <pre><code>msgcat --color=test\n</code></pre>"},{"location":"color/#putty-colors","title":"Putty Colors","text":"<p>We need to use <code>putty-256color</code> instead of <code>xterm-256color</code> or else the <code>Home</code> key is not working.</p> <p>Putty shows prompt with no color, but Linux SSH can In Putty, change Settings -&gt; Connection &gt; Data &gt; Terminal-type string to: <code>putty-256color</code>. \"Emulate\" 256 colors in PuTTY terminal</p> <ol> <li>Configure Putty</li> </ol> <p>In Settings &gt; Windows &gt; Colours there is a check box for \"Allow terminal to use xterm 256-colour mode\". 2. Let the app know</p> <p>You'll probably have to change Settings -&gt; Connection &gt; Data &gt; Terminal-type string to: <code>xterm-256color</code></p> <p>if your server has a terminfo entry for <code>putty-256color</code>, typically in <code>/usr/share/terminfo/p/putty-256color</code>, you can set <code>Putty</code>'s Terminal-Type to <code>putty-256color</code> instead.</p> <p>The main thing here is to make the server use an available <code>Terminfo</code> entry that most closely matches the way <code>Putty</code> is configured.</p>"},{"location":"color/#24bit","title":"24bit","text":"<ul> <li>Getting 24-bit color working in terminals</li> </ul>"},{"location":"color/#lscolors-schemes","title":"LSCOLORS Schemes","text":"<pre><code>for theme in $(vivid themes); do\n  echo \"Theme: $theme\";\n  LS_COLORS=$(vivid generate $theme);\n  ls;\n  echo;\ndone\nvivid generate one-light\nLSCOLORS=$(vivid generate one-light)\n</code></pre>"},{"location":"config_files/","title":"Configuration Files","text":"<ul> <li>Difference Between <code>.bashrc</code>, <code>.bash-profile</code>, and <code>.profile</code></li> <li>What are the functional differences between .profile .bash_profile and .bashrc</li> </ul> <p><code>.bash_profile</code> and <code>.bashrc</code> are specific to <code>bash</code>, whereas <code>.profile</code> is read by many shells in the absence of their own shell-specific config files. (<code>.profile</code> was used by the original Bourne shell.) <code>.bash_profile</code> or <code>.profile</code> is read by login shells, along with <code>.bashrc</code>; subshells read only <code>.bashrc</code>. (Between job control and modern windowing systems, <code>.bashrc</code> by itself doesn't get used much. If you use <code>screen</code> or <code>tmux</code>, screens/windows usually run subshells instead of login shells.)</p> <p>The idea behind this was that one-time setup was done by <code>.profile</code> (or shell-specific version thereof), and per-shell stuff by <code>.bashrc</code>. For example, you generally only want to load environment variables once per session instead of getting them whacked any time you launch a subshell within a session, whereas you always want your aliases (which aren't propagated automatically like environment variables are).</p> <p>Other notable shell config files:</p> <p><code>/etc/bash_profile</code> (fallback <code>/etc/profile</code>) is read before the user's .profile for system-wide configuration, and likewise <code>/etc/bashrc</code> in subshells (no fallback for this one). Many systems including Ubuntu also use an <code>/etc/profile.d</code> directory containing shell scriptlets, which are <code>.</code> (<code>source</code>)-ed from <code>/etc/profile</code>; the fragments here are per-shell, with <code>*.sh</code> applying to all Bourne/POSIX compatible shells and other extensions applying to that particular shell.</p>"},{"location":"doc/","title":"Tips-and-Tricks","text":""},{"location":"doc/#keep-sentence-pairs-for-sockeyes-length-limit","title":"Keep Sentence Pairs for Sockeye's Length Limit","text":"<p>Here's an example that keep sentence pairs that have less than 5 tokens.</p> <pre><code>paste &lt;(zcat OPUS-multiun-v1-eng-spa.spa.gz) &lt;(zcat OPUS-multiun-v1-eng-spa.eng.gz) \\\n| awk \\\n    -F'\\t' \\\n    'BEGIN {OFS = FS}  (split($1, a, \" +\")&lt;5 &amp;&amp; split($2, b, \" +\")&lt; 5) {print $1, $2}'\n</code></pre>"},{"location":"doc/#sort","title":"Sort","text":"<p>Sort according to a set of columns:</p> <pre><code>zcat FILE.gz | awk -F'\\t' '!_[$4,$5]++'\n</code></pre>"},{"location":"doc/#where-is-the-process-running","title":"Where is the process running","text":"<p>If there is a running process like <code>vim</code> that you would like to properly stop, you need to find in which <code>tmux</code> window it is running. To help figure this out, given the PID, you can ask <code>lsof</code> for its <code>CWD</code>.</p> <pre><code>lsof -a -d cwd -p PID\n</code></pre> <pre><code>COMMAND  PID    USER   FD   TYPE DEVICE SIZE/OFF      NODE NAME\nvim     7688 larkins  cwd    DIR   0,47     4096 154447160 /gpfs/projects/DT/mtp/models/HoC-Senate/corpora/spm/v2\n</code></pre>"},{"location":"doc/#filtering","title":"Filtering","text":""},{"location":"doc/#filtering-tsv-files-on-column","title":"Filtering tsv Files on Column","text":"<p>Filtering tsv files based on a subset of columns. Provided by Marc.</p> <pre><code># Filter-in\nawk \\\n  -F'\\t' \\\n  'NR==FNR{a[$4,$5];next} ($4,$5) in a' \\\n  uniq.DEVTEST_2022_${BIFILTER}.tsv \\\n  uniq.TRAIN_2021-2016_${BIFILTER}.tsv \\\n&gt; TRAIN_indev.tsv\n</code></pre> <pre><code># Filter-out\nawk \\\n  -F'\\t' \\\n  'NR==FNR{a[$4,$5];next} !(($4,$5) in a)' \\\n  uniq.DEVTEST_2022_${BIFILTER}.tsv \\\n  uniq.TRAIN_2021-2016_${BIFILTER}.tsv \\\n&gt; TRAIN_notindev.tsv\n</code></pre>"},{"location":"doc/#filter-out-testset-from-train","title":"Filter-out Testset From Train","text":"<pre><code>grep --text --line-regexp --invert-match --fixed-strings --file=$testset_filename\n</code></pre>"},{"location":"doc/#seeded-shuf","title":"Seeded <code>shuf</code>","text":"<pre><code>function get_seeded_random {\n  local -r seed=\"$1\"\n  openssl enc -aes-256-ctr -pass pass:\"$seed\" -nosalt &lt;/dev/zero 2&gt;/dev/null\n}\n\nshuf -i1-100 --random-source=&lt;(get_seeded_random 42)\n</code></pre>"},{"location":"doc/#broken-symlinks","title":"Broken Symlinks","text":"<pre><code>find . -type l ! -exec test -e {} \\; -print\n</code></pre>"},{"location":"doc/#refresh-bashs-cache","title":"Refresh Bash's Cache","text":"<p>How do I clear Bash's cache of paths to executables? <code>bash</code> does cache the full path to a command. You can verify that the command you are trying to execute is hashed with the type command:</p> <pre><code>type svnsync\nsvnsync is hashed (/usr/local/bin/svnsync)\n</code></pre> <p>To clear the entire cache:</p> <p><code>hash -r</code></p> <p>Or just one entry:</p> <p><code>hash -d svnsync</code></p> <p>For additional information, consult help hash and man bash.</p>"},{"location":"doc/#bash-debugging","title":"BASH debugging","text":"<ul> <li>Bash debugging - Youtube</li> <li><code>PS4</code> <code>export PS4='${BASH_SOURCE}:${LINENO}: ${FUNCNAME[0]}() - [${SHLVL},${BASH_SUBSHELL},$?] '</code></li> <li><code>bash -x</code></li> <li><code>bashdb</code></li> <li><code>shellcheck</code></li> </ul>"},{"location":"doc/#lvim","title":"<code>lvim</code>","text":"<p>Find commands <code>:WhichKey</code>. This opens a popup and if you type the shortcut key you get submenus.</p> <p><code>&lt;leader&gt;sT</code> where <code>&lt;leader&gt;</code> is <code>space</code> opens a popup to do fuzzy finding across files.</p> <p><code>&lt;leader&gt;f</code> find a file.</p>"},{"location":"doc/#gnu-parallel-a-la-spark","title":"GNU parallel a la Spark","text":"<pre><code>function desubtokenize {}\nexport -f desubtokenize\n\nfunction tokenize_corpus {}\nexport -f tokenize_corpus\n\nzcat --force train.gz \\\n| parallel \\\n  --spreadstdin \\\n  --recend '\\n' \\\n  --env desubtokenize \\\n  --env tokenize_corpus \\\n  \"desubtokenize | tokenize_corpus $lang\" \\\n&gt; train.tok.gz\n</code></pre>"},{"location":"doc/#weather","title":"Weather","text":"<p>wttr.in - GitHub: The right way to check the weather Get the weather:</p> <ul> <li><code>curl wttr.in/CityName</code></li> <li><code>curl v2d.wttr.in/CityName</code></li> </ul>"},{"location":"doc/#login-name","title":"Login Name","text":"<p>Find the full name of a user from its username.</p> <pre><code>lslogins | fzf\n</code></pre>"},{"location":"doc/#python","title":"Python","text":"<p>How to profile python's import statements. Used in finding expensive imports that slow down <code>--help</code>.</p> <pre><code>python -X importtime myscript.py\n</code></pre> <p>or:</p> <pre><code>PYTHONPROFILEIMPORTTIME=1 myscript.python\n</code></pre>"},{"location":"doc/#disk-usage","title":"Disk Usage","text":""},{"location":"doc/#tools","title":"Tools","text":"<ul> <li>diskus: A minimal, fast alternative to 'du -sh'</li> <li>dua: View disk space usage and delete unwanted data, fast.</li> <li>duc: Duc is a collection of tools for inspecting and visualizing disk usage</li> <li>dust: A more intuitive version of du in rust</li> <li>dutree: a tool to analyze file system usage written in Rust</li> <li>gdu: Fast disk usage analyzer with console interface written in Go</li> <li>godu: Simple golang utility helping to discover large files/folders.</li> <li>pdu: Highly parallelized, blazing fast directory tree analyzer</li> <li>tin-summer: Find build artifacts that are taking up disk space</li> </ul>"},{"location":"doc/#view-disk-usage-by-filetype","title":"View disk usage by filetype","text":"<pre><code>dust -t\n</code></pre> <pre><code> 3.0K   \u250c\u2500\u2500 (others)      \u2502                                             \u2588 \u2502   0%\n 2.0K   \u251c\u2500\u2500 .BLEU         \u2502                                             \u2588 \u2502   0%\n 2.0K   \u251c\u2500\u2500 .CHRF         \u2502                                             \u2588 \u2502   0%\n 2.0K   \u251c\u2500\u2500 .TER          \u2502                                             \u2588 \u2502   0%\n  64K   \u251c\u2500\u2500 .en           \u2502                                             \u2588 \u2502   0%\n  64K   \u251c\u2500\u2500 .sh           \u2502                                             \u2588 \u2502   0%\n  64K   \u251c\u2500\u2500 .train        \u2502                                             \u2588 \u2502   0%\n  64K   \u251c\u2500\u2500 .xz           \u2502                                             \u2588 \u2502   0%\n 128K   \u251c\u2500\u2500 .sharditer    \u2502                                             \u2588 \u2502   0%\n 130K   \u251c\u2500\u2500 .0            \u2502                                             \u2588 \u2502   0%\n 192K   \u251c\u2500\u2500 .log          \u2502                                             \u2588 \u2502   0%\n 832K   \u251c\u2500\u2500 .00000        \u2502                                             \u2588 \u2502   0%\n 1.3M   \u251c\u2500\u2500 (no extension)\u2502                                             \u2588 \u2502   0%\n 2.1M   \u251c\u2500\u2500 .fr           \u2502                                             \u2588 \u2502   0%\n 2.1M   \u251c\u2500\u2500 .gz           \u2502                                             \u2588 \u2502   0%\n 2.6M   \u251c\u2500\u2500 .out          \u2502                                             \u2588 \u2502   0%\n 3.3M   \u251c\u2500\u2500 .json         \u2502                                             \u2588 \u2502   0%\n 4.9M   \u251c\u2500\u2500 .word         \u2502                                             \u2588 \u2502   0%\n 799M   \u251c\u2500\u2500 .00001        \u2502                                    \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 \u2502  20%\n 3.1G   \u251c\u2500\u2500 .pkl          \u2502         \u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 \u2502  80%\n 3.9G \u250c\u2500\u2534 (total)         \u2502\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588 \u2502 100%\n</code></pre>"},{"location":"doc/#activate","title":"Activate","text":"<p>This is an example of an <code>activate</code> script when you compile a tool by hand and you don't install it a common place.</p> <pre><code>############ SENTENCEPIECE ############\n# Set this variable to override where Python is installed\n\n[ -n \"$SENTENCEPIECE_HOME\" ] &amp;&amp; echo \"NOT sourcing SENTENCEPIECE again\" &gt;&amp;2 &amp;&amp; return\n\n# Home\nexport SENTENCEPIECE_HOME=$(readlink -m $(dirname \"${BASH_SOURCE[0]}\"))\nexport SENTENCEPIECE_HOME=${SENTENCEPIECE_HOME_OVERRIDE:-$SENTENCEPIECE_HOME}\n\n# Binaries\nexport PATH=$SENTENCEPIECE_HOME/bin:$PATH\n\n# Libraries\nexport LIBRARY_PATH=$SENTENCEPIECE_HOME/lib64${LIBRARY_PATH:+:$LIBRARY_PATH}\nexport LD_LIBRARY_PATH=$SENTENCEPIECE_HOME/lib64${LD_LIBRARY_PATH:+:$LD_LIBRARY_PATH}\nexport LD_RUN_PATH=$SENTENCEPIECE_HOME/lib64${LD_RUN_PATH:+:$LD_RUN_PATH}\n\n# Includes\nexport CPLUS_INCLUDE_PATH=$SENTENCEPIECE_HOME/include${CPLUS_INCLUDE_PATH:+:$CPLUS_INCLUDE_PATH}\n\n# Package Configuration for ./configure to work when building other packages.\nexport PKG_CONFIG_PATH=$SENTENCEPIECE_HOME/lib/pkgconfig${PKG_CONFIG_PATH:+:$PKG_CONFIG_PATH}\n</code></pre>"},{"location":"doc/#grep-for-emojis","title":"Grep for Emojis","text":"<p>POSIX and Unicode character categories</p> <pre><code>ugrep '\\p{So}' input_file\n</code></pre>"},{"location":"fzf/","title":"fzf","text":""},{"location":"fzf/#tmux-fzf","title":"<code>tmux-fzf</code>","text":"<p>tmux-fzf: Use fzf to manage your tmux work environment!</p> <ul> <li>List of bindings</li> <li>prefix F  To launch tmux-fzf, press <code>prefix</code> + <code>F</code> (Shift+F).</li> </ul>"},{"location":"fzf/#fzf-gitsh","title":"<code>fzf-git.sh</code>","text":"<p>fzf-git.sh: bash and zsh key bindings for Git objects, powered by fzf.</p> <ul> <li>List of bindings</li> <li>CTRL-G CTRL-F for Files</li> <li>CTRL-G CTRL-B for Branches</li> <li>CTRL-G CTRL-T for Tags</li> <li>CTRL-G CTRL-R for Remotes</li> <li>CTRL-G CTRL-H for commit Hashes</li> <li>CTRL-G CTRL-S for Stashes</li> <li>CTRL-G CTRL-E for Each ref (<code>git for-each-ref</code>) <p>:warning: You may have issues with these bindings in the following cases:</p> <ul> <li>CTRL-G CTRL-B will not work if   CTRL-B is used as the tmux prefix</li> <li>CTRL-G CTRL-S will not work if flow control is enabled,   CTRL-S will freeze the terminal instead</li> <li>(<code>stty -ixon</code> will disable it)</li> </ul> <p>To workaround the problems, you can use CTRL-G {key} instead of CTRL-G CTRL-{KEY}.</p> </li> <li>Inside fzf</li> <li>TAB or SHIFT-TAB to select multiple objects</li> <li>CTRL-/ to change preview window layout</li> <li>CTRL-O to open the object in the web browser (in GitHub URL scheme)</li> </ul>"},{"location":"git/","title":"Git","text":""},{"location":"git/#remove-remote-branch-from-local","title":"Remove Remote Branch from Local","text":"<p>How to remove a remote branch ref from local (gh-pages)</p> <pre><code>git update-ref -d refs/remotes/origin/gh-pages\n</code></pre>"},{"location":"git/#how-to-delete-a-remote-branch","title":"How to Delete a Remote Branch","text":"<pre><code>git push origin --delete dev/semantic_diff\n</code></pre>"},{"location":"git/#realign-a-branch-with-origin","title":"Realign a Branch with <code>origin</code>","text":"<p>When you want to make your branch <code>BRANCH</code> the same as <code>origin/BRANCH</code> no matter what.</p> <pre><code>git swith BRANCH\ngit reset --hard origin/BRANC\n</code></pre>"},{"location":"git/#temporarily-disabled-delta-to-get-a-patch","title":"Temporarily Disabled <code>delta</code> to Get a Patch","text":"<p>To get a patch out of <code>git diff</code>, by the command to <code>less</code> which changes the pager from <code>delta</code> to <code>less</code>.</p> <pre><code>git diff main -- .pre-commit-config.yaml | less\n</code></pre>"},{"location":"git/#github","title":"GitHub","text":""},{"location":"git/#failed-ci-activity","title":"Failed CI activity","text":"<p>Delete all failed <code>CI activity</code> for a given user. Delete GitHub workflow runs using the gh cli</p> <pre><code>gh run list --status failure --user samuellarkin --json databaseId -q '.[].databaseId' \\\n| parallel --jobs  1 \"gh api repos/$(gh repo view --json nameWithOwner -q .nameWithOwner)/actions/runs/{} -X DELETE\"\n</code></pre>"},{"location":"git/#push-an-approved-prs-branch","title":"Push an Approved PR's branch","text":"<p>Once a PR is approved, you can use the following command to merge your <code>dev/work</code> branch to <code>main</code> given that your branch is at the tip of <code>main</code>. This effectively does a fast forward push from the CLI.</p> <pre><code>git push origin origin/dev/work:main\n</code></pre>"},{"location":"git/#find-which-pr-a-commit-belongs-to","title":"Find Which PR a Commit Belongs to","text":"<p>When you want to know a commit what added during which Pull Request:</p> <p>```sh git clone --mirror git@github.com:EveryVoiceTTS/EveryVoice.git EveryVoice-mirror cd EveryVoice-mirror/ sed -i 's|refs/pull/|refs/heads/pull/|' packed-refs git log --all --graph --decorate --oneline   # or your favourite compact log</p>"},{"location":"install/","title":"Install","text":""},{"location":"install/#unslothai","title":"Unsloth.ai","text":"<p>On GPSC7</p> <ul> <li>Set proxies(http and https) and correct <code>tmp</code> directories in <code>.profile</code></li> <li><code>nrc_profile.sh -c</code> : To update the profile</li> <li>Created user directory and set symlinks for <code>.cache</code> and <code>.conda</code></li> <li><code>conda create --name unsloth_env python=3.10</code></li> <li><code>source activate unsloth_env</code> : I didn't load moniconda module because that was introducing python 3.9 in the system path and I was not able to remove it.</li> <li><code>conda install pytorch-cuda=12.1 pytorch cudatoolkit xformers -c pytorch -c nvidia -c xformers</code></li> <li><code>pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"</code></li> <li><code>pip install --no-deps trl peft accelerate bitsandbytes</code></li> <li>I still got torch not found error, even though Step 7 was successful, so I just reinstalled it and then it worked.</li> <li>Launch jupyter in a job with <code>partition=gpu_a100</code>, <code>account=nrc_ict__gpu_a100</code> and <code>qos=low</code></li> </ul>"},{"location":"json/","title":"JSON/JSONL","text":""},{"location":"json/#compare","title":"Compare","text":"<p>Compare two jsonl files that are not in the same order. This implies that we need to sort the files on some <code>key</code>. Do a trick a la <code>Schwartian transform</code> where we prepend the sort <code>key</code>, sort on that <code>key</code> and the remove the <code>key</code>.</p> <pre><code>jqdiff \\\n  &lt;(zcat train.jsonl.gz \\\n    | jq --compact-output --raw-output '[.id, .|@text] | @tsv' \\\n    | sort -k1,1 \\\n    | cut -f2,2) \\\n  &lt;(zcat source/train.jsonl.gz \\\n    | jq --compact-output --raw-output '[.id, .|@text] | @tsv' \\\n    | sort -k1,1 \\\n    | cut -f 2,2)\n</code></pre> <p>Otherwise, use the alias <code>jqdiff</code> which essentially does</p> <pre><code>vimdiff &lt;(jq --sort-keys . file1.json) &lt;(jq --sort-keys . file2.json)\n</code></pre>"},{"location":"json/#parallel-processing","title":"Parallel Processing","text":"<p>Note that we use <code>--keep-order</code>, <code>--spreadstdin</code> &amp; <code>--recend='\\n'</code>.</p> <pre><code>function process {\n   cat\n}\nexport -f process\n\nzcat input.gz \\\n    | time \\parallel \\\n       --keep-order \\\n       --spreadstdin \\\n       --recend='\\n' \\\n       --env=process \\\n       'process' \\\n| gzip \\\n&gt; output.gz\n</code></pre>"},{"location":"json/#counting-elements","title":"Counting Elements","text":"<p>Count the number of entries/sentence pairs that have the <code>.unparsable</code> key.</p> <pre><code>pv Huge.jsonl \\\n| jq --null-input '[ inputs | select(.unparsable)] | reduce .[] as $item (0; . + 1)'\n</code></pre>"},{"location":"json/#group-by-x-and-merge","title":"Group by X and Merge","text":"<p>Context: after generating <code>*.scores.json</code> using <code>sacrebleu  --width=14 reference --metrics bleu chrf ter  &lt; translation &gt; scores.json</code>. Can we extract BLEU scores from all our experiments and tabulate the result using <code>mlr</code>?</p> <pre><code>find -type f -name \\*scores.json \\\n| xargs dirname \\\n| parallel 'jq \"{\\\"expt_name\\\": \\\"{//}\\\",  \\\"{/}\\\": (.[] | select(.name == \\\"BLEU\\\") | .score)}\" {}/*scores.json' \\\n| jq --slurp --sort-keys 'group_by(.expt_name) | [.[] | add]' \\\n| mlr --json --opprint --barred cat \\\n| less\n</code></pre>"},{"location":"json/#aggregate-a-field","title":"Aggregate a Field","text":"<p>Given a list of objects where some of them have the same <code>id</code> but with a field with different values, aggregate that field for each object. This happens when you extracted data from <code>mysql</code>. <code>mysql</code> doesn't allow subqueries to return multiple rows with multiple columns thus you have to do the same work using <code>JOIN</code>. Merge Arrays of JSON</p> <pre><code>echo -e '{\"id\":1, \"b\":[{\"c\":1}]}{\"id\":1, \"b\":[{\"c\":2}]}'\n</code></pre> <pre><code>{\n  \"id\": 1,\n  \"b\": [\n    {\n      \"c\": 1\n    }\n  ]\n}\n{\n  \"id\": 1,\n  \"b\": [\n    {\n      \"c\": 2\n    }\n  ]\n}\n</code></pre> <ul> <li>group entries by <code>id</code></li> <li>for each group</li> <li>take the first element and aggregate all of the <code>b</code> in a list</li> <li>return that first element that has been augmented with a list of <code>b</code></li> </ul> <pre><code>echo -e '{\"id\":1, \"b\":[{\"c\":1}]}{\"id\":1, \"b\":[{\"c\":2}]}' \\\n| jq --slurp 'group_by(.id) | .[] | (.[0].b=([.[].b]|flatten)) | .[0]'\n</code></pre> <pre><code>{\n  \"id\": 1,\n  \"b\": [\n    {\n      \"c\": 1\n    },\n    {\n      \"c\": 2\n    }\n  ]\n}\n</code></pre>"},{"location":"json/#zip-multiple-files","title":"Zip Multiple files","text":"<p>Merge arrays The key here is the <code>transpose</code>.</p> <pre><code>zcat translation.fr.json.gz \\\n| jq \\\n    --slurp \\\n    --argfile src &lt;(jq -R '{\"src\":.}' source.en) \\\n    --argfile ref &lt;(jq -R '{\"ref\":.}' reference.fr) \\\n    '[., $src, $ref] | transpose | map(add) | .[]'\n</code></pre>"},{"location":"json/#flat-files-to-structured-json","title":"Flat Files to Structured json","text":"<p>When you have multiple flat files that you want to combine into a structured json.</p> <p>lingua_eng_spa/Tilde-worldbank-1-eng-spa.spa.gz</p> <pre><code>SPA     0.9998978843092705\nSPA     0.9991979235059277\n</code></pre> <p>lingua_all_languages/Tilde-worldbank-1-eng-spa.spa.gz</p> <pre><code>SPA     0.9999975457963204\nSPA     0.9847735076254288\n</code></pre> <p>Tilde-worldbank-1-eng-spa.spa.gz</p> <pre><code>\"Igualmente, hacemos notar la importancia de abordar el problema del hambre y la malnutrici\u00f3n\u201d.\n\"La vida es muy dif\u00edcil.\n</code></pre> <p>Tilde-worldbank-1-eng-spa.eng.gz</p> <pre><code>\" We also note the importance of addressing hunger and malnutrition.\u201d\n\"[Life] is extremely difficult.\n</code></pre> <pre><code>paste \\\n  &lt;(zcat lingua_eng_spa/Tilde-worldbank-1-eng-spa.spa.gz) \\\n  &lt;(zcat lingua_all_languages/Tilde-worldbank-1-eng-spa.spa.gz) \\\n  &lt;(zcat Tilde-worldbank-1-eng-spa.spa.gz) \\\n  &lt;(zcat Tilde-worldbank-1-eng-spa.eng.gz) \\\n| mlr --tsv --ojson --implicit-csv-header \\\n  label eng_spa.lid,eng_spa.confidence,all.lid,all.confidence,spa,eng \\\n| jq '.[]'\n</code></pre> <pre><code>{\n  \"eng_spa\": {\n    \"lid\": \"SPA\",\n    \"confidence\": 0.9998978843092705\n  },\n  \"all\": {\n    \"lid\": \"SPA\",\n    \"confidence\": 0.9999975457963204\n  },\n  \"spa\": \"\\\"Igualmente, hacemos notar la importancia de abordar el problema del hambre y la malnutrici\u00f3n\u201d.\",\n  \"eng\": \"\\\" We also note the importance of addressing hunger and malnutrition.\u201d\"\n}\n{\n  \"eng_spa\": {\n    \"lid\": \"SPA\",\n    \"confidence\": 0.9991979235059277\n  },\n  \"all\": {\n    \"lid\": \"SPA\",\n    \"confidence\": 0.9847735076254288\n  },\n  \"spa\": \"\\\"La vida es muy dif\u00edcil.\",\n  \"eng\": \"\\\"[Life] is extremely difficult.\"\n}\n</code></pre>"},{"location":"json/#xml-to-json","title":"XML to json","text":"<p>Using yq, we can convert a xml document into a json file.</p> <pre><code>yq -p xml -o json &lt; input.xml &gt; output.json\n</code></pre>"},{"location":"json/#convert-to-array","title":"Convert to Array","text":"<p>Given</p> <pre><code>[\n  { \"seg\": [\"A\", \"B\"] },\n  { \"seg\": \"C\"},\n]\n</code></pre> <p>The second object is NOT an array but you need it to be an array to process all elements the same way, you can make sure all segments are arrays by doing:</p> <pre><code>jq '.[] | .seg | (if type == \"object\" then [.] else . end) | .[]'\n</code></pre>"},{"location":"json/#filter-out-subobjects","title":"Filter-out SubObjects","text":"<p>Given</p> <pre><code>&lt;?xml version='1.0' encoding='utf-8'?&gt;\n&lt;dataset id=\"wmttest2024\"&gt;\n  &lt;collection id=\"general\"&gt;\n    &lt;doc origlang=\"en\" id=\"test-en-news_beverly_press.3585\" domain=\"news\"&gt;\n      &lt;src lang=\"en\"&gt;\n        &lt;p&gt;\n          &lt;seg id=\"1\"&gt;Siso's depictions of land, water center new gallery exhibition&lt;/seg&gt;\n        &lt;/p&gt;\n      &lt;/src&gt;\n      &lt;ref lang=\"es\" translator=\"refA\"&gt;\n        &lt;p&gt;\n          &lt;seg id=\"1\"&gt;Representaciones de la tierra y el agua de Siso centran una nueva exposici\u00f3n&lt;/seg&gt;\n        &lt;/p&gt;\n      &lt;/ref&gt;\n    &lt;/doc&gt;\n    &lt;doc origlang=\"en\" id=\"test-en-news_brisbanetimes.com.au.228963\" domain=\"NOT_news\"&gt;\n      &lt;src lang=\"en\"&gt;\n        &lt;p&gt;\n          &lt;seg id=\"1\"&gt;Adapt the old, accommodate the new to solve issue&lt;/seg&gt;\n        &lt;/p&gt;\n      &lt;/src&gt;\n      &lt;ref lang=\"es\" translator=\"refA\"&gt;\n        &lt;p&gt;\n          &lt;seg id=\"1\"&gt;Adapta lo viejo, incorpora lo nuevo para resolver el problema&lt;/seg&gt;\n        &lt;/p&gt;\n      &lt;/ref&gt;\n    &lt;/doc&gt;\n  &lt;/collection&gt;\n&lt;/dataset&gt;\n</code></pre> <p>Remove documents that are NOT of <code>news</code> domain keeping the document's structure.</p> <pre><code>~/.local/bin/yq 'del(.dataset.collection.doc[] | select(.[\"+@domain\"] != \"news\"))' wmttest2024.en-es.xml\n</code></pre> <pre><code>&lt;?xml version='1.0' encoding='utf-8'?&gt;\n&lt;dataset id=\"wmttest2024\"&gt;\n  &lt;collection id=\"general\"&gt;\n    &lt;doc origlang=\"en\" id=\"test-en-news_beverly_press.3585\" domain=\"news\"&gt;\n      &lt;src lang=\"en\"&gt;\n        &lt;p&gt;\n          &lt;seg id=\"1\"&gt;Siso's depictions of land, water center new gallery exhibition&lt;/seg&gt;\n        &lt;/p&gt;\n      &lt;/src&gt;\n      &lt;ref lang=\"es\" translator=\"refA\"&gt;\n        &lt;p&gt;\n          &lt;seg id=\"1\"&gt;Representaciones de la tierra y el agua de Siso centran una nueva exposici\u00f3n&lt;/seg&gt;\n        &lt;/p&gt;\n      &lt;/ref&gt;\n    &lt;/doc&gt;\n  &lt;/collection&gt;\n&lt;/dataset&gt;\n</code></pre>"},{"location":"miller/","title":"miller","text":"<ul> <li>Documentation</li> <li>GitHub: Miller is like awk, sed, cut, join, and sort for name-indexed data such as CSV, TSV, and tabular JSON.</li> </ul>"},{"location":"miller/#tabulate-bleu-scores","title":"Tabulate BLEU Scores","text":"<ul> <li>Reading a csv dataframe</li> <li>Write a nice table using bars</li> <li>Print numbers with 2 decimal</li> <li>cut: keep column based on a list of regular expressions</li> <li>merge-fields: add a <code>mean</code> column calculating the mean of columns</li> <li>reorder: move the datetime column at the end of the table</li> <li>label: renamed the columns</li> <li>sort: on <code>test</code> to rank the rows</li> <li>put: add the row's rank</li> <li>sort: reorder <code>on expt_name</code></li> </ul> <pre><code>  score-tool tabulate --no-title \\\n  | mlr --icsv --opprint --barred --ofmt %.2f \\\n    cut -rf expt_name,$suffix,date \\\n    then merge-fields  -a mean  -r $suffix  -o $suffix  -k \\\n    then reorder -e -f datetime \\\n    then label expt_name,test,validation,mean,datetime \\\n    then sort -nr test \\\n    then put 'begin {@rank = 1} $rank = @rank; @rank += 1' \\\n    then sort -nr expt_name\n</code></pre>"},{"location":"miller/#find-hoc-sittings-elapsed-time","title":"Find HoC Sittings Elapsed Time","text":"<pre><code>bzcat sentence_word_count_fr.tsv.bz2 | head -n 3\n</code></pre> <pre><code>id      datetime        wc      sentence\nHouse/House/391/Debates/001/HAN001      2006-04-03 11:05:00.000000      49      The 38th Parliament ...\nHouse/House/391/Debates/001/HAN001      2006-04-03 11:05:00.001000      5       Monday, April 3, 2006\n</code></pre> <ul> <li>Transform <code>$datestamp</code> into the number of second since epoch 0</li> <li>Find the minimum and maximum datetime for each Sitting</li> <li>Figure out the elpase time</li> <li>Convert the start and end time back to a datetime</li> <li>Discard unwanted fields by specifying which one we want to keep</li> <li>Reorder the fields</li> </ul> <pre><code>bzcat sentence_word_count_fr.tsv.bz2 \\\n| head -n 10000 \\\n| mlr --itsv --opprint --barred \\\n  cut -x -f sentence then put '$datestamp = strptime($datetime, \"%Y-%m-%d %T.%f\")' \\\n  then \\\n  stats1 -g id -f datestamp -a min,max \\\n  then \\\n  put '$elapse = $datestamp_max - $datestamp_min'\n  then \\\n  put '$start = strftime($datestamp_min, \"%Y-%m-%d %T\"); $end = strftime($datestamp_max, \"%Y-%m-%d %T\")' \\\n  then \\\n  cut -f id,start,end,elapse \\\n  then \\\n  reorder -f id,start,end,elapse\n</code></pre> <pre><code>+------------------------------------+---------------------+---------------------+--------------------+\n| id                                 | start               | end                 | elapse             |\n+------------------------------------+---------------------+---------------------+--------------------+\n| House/House/391/Debates/001/HAN001 | 2006-04-03 11:05:00 | 2006-04-03 14:05:00 | 10800.12400007248  |\n| House/House/391/Debates/002/HAN002 | 2006-04-04 00:00:00 | 2006-04-04 17:05:00 | 61500.206000089645 |\n| House/House/391/Debates/003/HAN003 | 2006-04-05 00:00:00 | 2006-04-05 18:25:00 | 66300.73900008202  |\n| House/House/391/Debates/004/HAN004 | 2006-04-06 00:00:00 | 2006-04-06 23:15:01 | 83701.97799992561  |\n| House/House/391/Debates/005/HAN005 | 2006-04-07 00:00:00 | 2006-04-07 14:30:00 | 52200.70899987221  |\n| House/House/391/Debates/006/HAN006 | 2006-04-10 00:00:00 | 2006-04-10 11:35:00 | 41700.10199999809  |\n+------------------------------------+---------------------+---------------------+--------------------+\n</code></pre>"},{"location":"miller/#group-per-date","title":"Group per Date","text":"<pre><code>jq --raw-output --compact-output \\\n   '{\"date\": (.timestamp|split(\" \")[0]), \"fr\": (.fr|split(\" \") | length), \"en\": (.en|split(\" \")|length)}' \\\n| mlr --ijson \\\n  then stats1 -a sum,count -f en,fr -g date \\\n  then cut -x -f en_count \\\n  then rename en_sum,#en_word,fr_sum,#fr_word,fr_count,#sentence \\\n| mlr --opprint --barred summary -a count,null_count,distinct_count,mean,min,median,max,stddev\n</code></pre> <pre><code>{\"date\":\"2022-10-24\",\"fr\":18,\"en\":15}\n{\"date\":\"2022-10-24\",\"fr\":18,\"en\":18}\n{\"date\":\"2022-10-24\",\"fr\":29,\"en\":28}\n</code></pre> <pre><code>date=2022-10-24,#en_word=55951,#fr_word=59892,#sentence=2692\ndate=2022-10-25,#en_word=73587,#fr_word=79288,#sentence=3660\ndate=2022-10-26,#en_word=29726,#fr_word=32800,#sentence=1492\n</code></pre> field_name count null_count distinct_count mean stddev min median max date 112 0 112 2022-10-24 2023-03-23 2023-09-29 #en_word 112 0 112 64893.669642857145 25599.55527604576 2812 68386 123193 #fr_word 112 0 112 71302.02678571429 27863.87682146542 3150 76163 133257 #sentence 112 0 112 3282.6160714285716 1318.6068832416186 128 3502 6373"},{"location":"miller/#group-per-object","title":"Group per Object","text":"<pre><code>jq --raw-output --compact-output \\\n   '{\"sitting\": (.doc | {parliament, session, number})} + {\"fr\": (.fr|split(\" \") | length), \"en\": (.en|split(\" \")|length)}' \\\n| mlr --ijson \\\n   then stats1 -a sum,count -f en,fr -g sitting \\\n   then cut -x -f en_count \\\n   then rename en_sum,#en_word,fr_sum,#fr_word,fr_count,#sentence \\\n| mlr --opprint --barred summary -a count,null_count,distinct_count,mean,min,median,max,stddev\n</code></pre> <pre><code>{\"sitting\":{\"parliament\":44,\"session\":1,\"number\":116},\"fr\":18,\"en\":15}\n{\"sitting\":{\"parliament\":44,\"session\":1,\"number\":116},\"fr\":18,\"en\":18}\n{\"sitting\":{\"parliament\":44,\"session\":1,\"number\":116},\"fr\":29,\"en\":28}\n</code></pre> <pre><code>sitting.parliament=44,sitting.session=1,sitting.number=116,#en_word=55951,#fr_word=59892,#sentence=2692\nsitting.parliament=44,sitting.session=1,sitting.number=117,#en_word=73587,#fr_word=79288,#sentence=3660\nsitting.parliament=44,sitting.session=1,sitting.number=118,#en_word=29726,#fr_word=32800,#sentence=1492\n</code></pre> field_name count null_count distinct_count mean stddev min median max sitting.parliament 111 0 1 44 0 44 44 44 sitting.session 111 0 1 1 0 1 1 1 sitting.number 111 0 111 171.44144144144144 32.61697402069964 116 171 227 #en_word 111 0 111 65478.2972972973 25569.833917971166 23026 68386 131905 #fr_word 111 0 110 71944.38738738738 27816.245672487912 25521 76163 142068 #sentence 111 0 110 3312.189189189189 1315.06589889158 1147 3502 6588"},{"location":"nvim/","title":"Neovim","text":"<ul> <li>Popular Neovim Configurations</li> <li>Christian Chiarulli's neovim config</li> </ul>"},{"location":"nvim/#tips-and-tricks","title":"Tips-And-Tricks","text":"<ul> <li>Is it possible to disable lsp formatting temporarily?    You can avoid all autocommands with <code>:noa w</code>, or ignore some (or all) for some time with <code>:set eventignore=BufWritePre</code>.</li> <li>Replace <code>gq{motion}</code> by <code>gw{motion}</code> to format the lines that {motion} moves over.</li> </ul>"},{"location":"nvim/#lazyvim","title":"LazyVim","text":"<p>LazyVim is a collection of plugins and is built on top of lazy.vim. LazyVim is a Neovim setup powered by \ud83d\udca4 lazy.nvim to make it easy to customize and extend your config.</p> <ul> <li>LazyVim</li> <li>GitHub: Neovim config for the lazy</li> <li>GitHub - lazy.vim: \ud83d\udca4 A modern plugin manager for Neovim</li> </ul>"},{"location":"nvim/#treesitter","title":"TreeSitter","text":"<p>TreeSitter in <code>nvim</code> is used for better syntax highlighting.</p> <p>Tree-sitter is a parser generator tool and an incremental parsing library. It can build a concrete syntax tree for a source file and efficiently update the syntax tree as the source file is edited. Tree-sitter aims to be:</p> <ul> <li>General enough to parse any programming language</li> <li>Fast enough to parse on every keystroke in a text editor</li> <li>Robust enough to provide useful results even in the presence of syntax errors</li> <li> <p>Dependency-free so that the runtime library (which is written in pure C) can be embedded in any application</p> </li> <li> <p>tree-sitter: An incremental parsing system for programming tools</p> </li> <li>Documentation</li> <li>nvim-treesitter: Nvim Treesitter configurations and abstraction layer</li> </ul>"},{"location":"nvim/#nvim-treesitter-textobjects","title":"nvim-treesitter-textobjects","text":"<p>github: Syntax aware text-objects, select, move, swap, and peek support.</p>"},{"location":"nvim/#nvim-treesitter-context","title":"nvim-treesitter-context","text":"<p>github: Show the function you are in at the top of the buffer.</p> <p>A Vim plugin that shows the context of the currently visible buffer contents. It's supposed to work on a wide range of file types, but is probably most useful when looking at source code files. In most programming languages this context will show you which function you're looking at, and within that function which loops or conditions are surrounding the visible code.</p>"},{"location":"nvim/#telescope","title":"Telescope","text":""},{"location":"nvim/#telescopenvim","title":"telescope.nvim","text":"<p>github: Find, Filter, Preview, Pick. All lua, all the time.</p>"},{"location":"nvim/#telescope-fzf-nativenvim","title":"telescope-fzf-native.nvim","text":"<p>github: FZF sorter for telescope written in c. <code>fzf-native</code> is a <code>c</code> port of <code>fzf</code>. It only covers the algorithm and implements few functions to support calculating the score.</p>"},{"location":"nvim/#which-keynvim","title":"which-key.nvim","text":"<p>github: \ud83d\udca5 Create key bindings that stick. WhichKey is a lua plugin for Neovim 0.5 that displays a popup with possible keybindings of the command you started typing.</p>"},{"location":"nvim/#gitsignsnvim","title":"gitsigns.nvim","text":"<p>Equivalent to VCSVimdiff</p> <p>github: Git integration for buffers. Super fast git decorations implemented purely in Lua.</p> <p>Features</p> <ul> <li>Signs for added, removed, and changed lines</li> <li>Asynchronous using luv</li> <li>Navigation between hunks</li> <li>Stage hunks (with undo)</li> <li>Preview diffs of hunks (with word diff)</li> <li>Customizable (signs, highlights, mappings, etc)</li> <li>Status bar integration</li> <li>Git blame a specific line using virtual text.</li> <li>Hunk text object</li> <li>Automatically follow files moved in the index.</li> <li>Live intra-line word diff</li> <li>Ability to display deleted/changed lines via virtual lines.</li> <li>Support for yadm</li> <li>Support for detached working trees.</li> </ul>"},{"location":"nvim/#vim-illuminate","title":"vim-illuminate","text":"<p>github: illuminate.vim - (Neo)Vim plugin for automatically highlighting other uses of the word under the cursor using either LSP, Tree-sitter, or regex matching.</p>"},{"location":"nvim/#troublenvim","title":"trouble.Nvim","text":"<p>github: \ud83d\udea6 A pretty diagnostics, references, telescope results, quickfix and location list to help you solve all the trouble your code is causing.</p>"},{"location":"nvim/#language-sever-protocol-lsp","title":"Language Sever Protocol (LSP)","text":""},{"location":"nvim/#masonnvim","title":"mason.nvim","text":"<p>github: Portable package manager for Neovim that runs everywhere Neovim runs. Easily install and manage LSP servers, DAP servers, linters, and formatters.</p> <p><code>:h mason-introduction</code></p> <p><code>mason.nvim</code> is a Neovim plugin that allows you to easily manage external editor tooling such as LSP servers, DAP servers, linters, and formatters through a single interface. It runs everywhere Neovim runs (across Linux, macOS, Windows, etc.), with only a small set of external requirements needed.</p> <p>Packages are installed in Neovim's data directory (<code>:h standard-path</code>) by default. Executables are linked to a single <code>bin/</code> directory, which <code>mason.nvim</code> will add to Neovim's PATH during setup, allowing seamless access from Neovim builtins (shell, terminal, etc.) as well as other 3rd party plugins.</p> <p>For a list of all available packages, see https://mason-registry.dev/registry/list.</p>"},{"location":"nvim/#noicenvim","title":"noice.nvim","text":"<p>github: \ud83d\udca5 Highly experimental plugin that completely replaces the UI for messages, cmdline and the popupmenu.</p>"},{"location":"nvim/#miniindentscopre","title":"mini.indentscopre","text":"<p>github: Neovim Lua plugin to visualize and operate on indent scope. Part of 'mini.nvim' library.</p>"},{"location":"nvim/#lualinenvim","title":"lualine.nvim","text":"<p>github: A blazing fast and easy to configure neovim statusline plugin written in pure lua.</p>"},{"location":"nvim/#luasnip","title":"LuaSnip","text":"<p>github: Snippet Engine for Neovim written in Lua.</p>"},{"location":"nvim/#nvim-cmp","title":"nvim-cmp","text":"<p>github: A completion plugin for neovim coded in Lua. A completion engine plugin for neovim written in Lua. Completion sources are installed from external repositories and \"sourced\".</p>"},{"location":"nvim/#cmp-nvim-lsp","title":"cmp-nvim-lsp","text":"<p>github: nvim-cmp source for neovim builtin LSP client.</p> <p>Language servers provide different completion results depending on the capabilities of the client. Neovim's default omnifunc has basic support for serving completion candidates. <code>nvim-cmp</code> supports more types of completion candidates, so users must override the capabilities sent to the server such that it can provide these candidates during a completion request. These capabilities are provided via the helper function <code>require('cmp_nvim_lsp').default_capabilities</code></p> <p>As these candidates are sent on each request, adding these capabilities will break the built-in omnifunc support for neovim's language server client. <code>nvim-cmp</code> provides manually triggered completion that can replace omnifunc. See <code>:help cmp-faq</code> for more details.</p>"},{"location":"nvim/#cmp-buffer","title":"cmp-buffer","text":"<p>github: nvim-cmp source for buffer words.</p>"},{"location":"nvim/#cmp-path","title":"cmp-path","text":"<p>github: nvim-cmp source for filesystem paths.</p>"},{"location":"nvim/#cmp_luasnip","title":"cmp_luasnip","text":"<p>github: luasnip completion source for nvim-cmp</p>"},{"location":"nvim/#minipairs","title":"mini.pairs","text":"<p>github: Neovim Lua plugin to automatically manage character pairs. Part of 'mini.nvim' library.</p>"},{"location":"nvim/#minisurround","title":"mini.surround","text":"<p>github: Neovim Lua plugin with fast and feature-rich surround actions. Part of 'mini.nvim' library.</p>"},{"location":"nvim/#miniai","title":"mini.ai","text":"<p>github: Neovim Lua plugin to extend and create <code>a</code>/<code>i</code> textobjects. Part of 'mini.nvim' library.</p>"},{"location":"nvim/#minicomment","title":"mini.comment","text":"<p>github: Neovim Lua plugin for fast and familiar per-line commenting. Part of 'mini.nvim' library.</p>"},{"location":"nvim/#nvim-notify","title":"nvim-notify","text":"<p>github: A fancy, configurable, notification manager for NeoVim.</p>"},{"location":"perl/","title":"Perl","text":""},{"location":"perl/#remove-repeating-chinese-characters","title":"Remove Repeating Chinese Characters","text":"<pre><code>perl -ple 'BEGIN{use utf8;use open qw(:std :utf8);} s/(\\p{Han})\\1{1,}/\\1/gm' &lt; translation.zho.word\n</code></pre>"},{"location":"rsync/","title":"rsync","text":"<p>rsync copy over only certain types of files using include option  NOTE you MUST add <code>--include='*/'</code> to let rsync at least visit all directories.</p> <pre><code>rsync \\\n  -Parzu \\\n  -m \\\n  --include='*/' \\\n  --include='*/run_mlm.config' \\\n  --include='*/trainer.py' \\\n  --exclude='*' \\\n  xlm-roberta-large.2500.min_prob.emb \\\n  xlm-roberta-large.2500.not_sorted.emb \\\n  xlm-roberta-large.5000.min_prob.emb \\\n  xlm-roberta-large.5000.not_sorted.emb \\\n  ../mt/ \\\n  -n\n</code></pre> <p>How to use Rsync to copy only specific subdirectories (same names in several directories)</p> <pre><code>rsync \\\n  -F \\\n  -Parzu \\\n  gpsc5:/space/project/portage/models/WMT2023 \\\n  /gpfs/projects/DT/mtp/models/ \\\n  --include='*/' \\\n  --include='*/wmttest2023.splited' \\\n  --include='wmttest2023.splited/***' \\\n  --exclude='*' \\\n  -n\n</code></pre>"},{"location":"rsync/#clone-an-experiments-structure","title":"Clone an Experiment's Structure","text":"<pre><code>rsync \\\n  -Parzu \\\n  -m \\\n  --include='*/' \\\n  --include='*/expt_config' \\\n  --include='*/model_config.yaml' \\\n  --include='*/prep.sh' \\\n  --exclude='*' \\\n  ../en2fr.2024-03-19/finetuning \\\n  .\n</code></pre>"},{"location":"slurm/","title":"SLURM","text":""},{"location":"slurm/#job-command-and-information","title":"Job Command and Information","text":""},{"location":"slurm/#update-a-job","title":"Update a job","text":"<p>Add a dependency to run a job after another job.</p> <pre><code>scontrol update jobid=&lt;JOBID&gt; dependency=afterok:&lt;PREVIOUS_JOBID&gt;\n</code></pre> <p>Add dependencies to multiple jobs</p> <pre><code>scontrol \\\n  update \\\n    jobid=$(echo {15882..15893} | tr ' ' ',')\n    dependency=afterok:15754:15756:15757:15758:15765:15766:15767:15740:15743\n</code></pre> <p>Change the time limit.</p> <pre><code>scontrol update jobid=&lt;JOBID&gt; TimeLimit=&lt;NEW_TIMELIMIT&gt;\n</code></pre> <p>Change the number of maximum concurrent tasks.</p> <pre><code>scontrol update jobid=&lt;JOBID&gt; ArrayTaskThrottle=0\n</code></pre>"},{"location":"slurm/#a-scriptless-job","title":"A Scriptless Job","text":"<p>Running a binary without a top level script in SLURM</p> <pre><code> sbatch \\\n   --time=00:20:00 \\\n   --partition=TrixieMain,JobTesting \\\n   --account=dt-mtp \\\n   --nodes=1 \\\n   --ntasks-per-node=1 \\\n   --cpus-per-task=40 \\\n   --mem=40G \\\n   --wrap='time python -m sockeye.translate --output-type json --batch-size 32 --models base_model --input corpora/validation.en --use-cpu &gt; model/decode.output.0.00000.json'\n</code></pre>"},{"location":"slurm/#jobs-information","title":"Job's Information","text":"<p>List detailed information for a job (useful for troubleshooting):</p> <pre><code>scontrol show jobid --details &lt;JOBID&gt;\n</code></pre> <pre><code>JobId=403641 JobName=HoC-CL.training\n   UserId=larkins(171967808) GroupId=larkins(171967808) MCS_label=N/A\n   Priority=68528 Nice=0 Account=dt-mtp QOS=normal\n   JobState=PENDING Reason=ReqNodeNotAvail,_Reserved_for_maintenance Dependency=(null)\n   Requeue=1 Restarts=1 BatchFlag=1 Reboot=0 ExitCode=0:0\n   DerivedExitCode=0:0\n   RunTime=00:00:00 TimeLimit=12:00:00 TimeMin=N/A\n   SubmitTime=2024-01-19T04:39:27 EligibleTime=2024-01-19T04:41:28\n   AccrueTime=2024-01-19T04:41:28\n   StartTime=2024-01-21T14:30:00 EndTime=2024-01-22T02:30:00 Deadline=N/A\n   SuspendTime=None SecsPreSuspend=0 LastSchedEval=2024-01-19T10:13:15\n   Partition=TrixieMain AllocNode:Sid=hn2:20782\n   ReqNodeList=(null) ExcNodeList=cn119\n   NodeList=(null)\n   BatchHost=cn120\n   NumNodes=1 NumCPUs=24 NumTasks=4 CPUs/Task=6 ReqB:S:C:T=0:0:*:*\n   TRES=cpu=24,mem=96G,node=1,billing=24,gres/gpu=4\n   Socks/Node=* NtasksPerN:B:S:C=4:0:*:* CoreSpec=*\n   MinCPUsNode=24 MinMemoryNode=96G MinTmpDiskNode=0\n   Features=(null) DelayBoot=00:00:00\n   OverSubscribe=OK Contiguous=0 Licenses=(null) Network=(null)\n   Command=/gpfs/projects/DT/mtp/models/HoC-ContinualLearning/nmt/tools/train.sh\n   WorkDir=/gpfs/projects/DT/mtp/models/HoC-ContinualLearning/nmt/en2fr/baseline_initial\n   Comment=House of Commons Continual Learning NMT training\n   StdErr=/gpfs/projects/DT/mtp/models/HoC-ContinualLearning/nmt/en2fr/baseline_initial/HoC-CL.training-403641.out\n   StdIn=/dev/null\n   StdOut=/gpfs/projects/DT/mtp/models/HoC-ContinualLearning/nmt/en2fr/baseline_initial/HoC-CL.training-403641.out\n   Power=\n   TresPerNode=gpu:4\n</code></pre> <p>Find out where a job will run</p> <pre><code>scontrol show job &lt;JOBID&gt;\n</code></pre>"},{"location":"slurm/#tabulate-the-information-of-queued-jobs","title":"Tabulate the Information of Queued jobs","text":"<p>If you are running a lot of jobs and need to inspect some of them for some feature, example, what command they will run, use <code>mlr</code>.</p> <pre><code>squeue --Format='JobID' --user=$USER --noheader \\\n| \\parallel 'scontrol --oneliner show job {}' \\\n| sed 's/ /,/g' \\\n| mlr --opprint cat \\\n| less\n</code></pre>"},{"location":"slurm/#stats-of-a-job","title":"Stats of a job","text":"<p>Get some stats about a job that ran on <code>Slurm</code>. Get stats about a job that has finished.</p> <pre><code>sacct --long --jobs=&lt;JOBID&gt;\nsacct -l -j &lt;JOBID&gt;\n</code></pre>"},{"location":"slurm/#cluster-information","title":"Cluster information","text":"<p>See what the nodes really offer.</p> <pre><code>scontrol show nodes\n</code></pre> <pre><code>NodeName=cn136 Arch=x86_64 CoresPerSocket=16\n   CPUAlloc=0 CPUTot=64 CPULoad=0.01\n   AvailableFeatures=(null)\n   ActiveFeatures=(null)\n   Gres=gpu:4\n   NodeAddr=cn136 NodeHostName=cn136\n   OS=Linux 3.10.0-1160.62.1.el7.x86_64 #1 SMP Tue Apr 5 16:57:59 UTC 2022\n   RealMemory=192777 AllocMem=0 FreeMem=176763 Sockets=2 Boards=1\n   State=IDLE ThreadsPerCore=2 TmpDisk=0 Weight=1 Owner=N/A MCS_label=N/A\n   Partitions=JobTesting\n   BootTime=2023-09-21T07:56:52 SlurmdStartTime=2023-09-21T07:57:17\n   CfgTRES=cpu=64,mem=192777M,billing=64,gres/gpu=4\n   AllocTRES=\n   CapWatts=n/a\n   CurrentWatts=0 AveWatts=0\n   ExtSensorsJoules=n/s ExtSensorsWatts=0 ExtSensorsTemp=n/s\n</code></pre> <p>See the information of an upcoming maintenance.</p> <pre><code>scontrol show reservation\n</code></pre> <pre><code>ReservationName=maintenance2 StartTime=2024-01-19T14:30:00 EndTime=2024-01-21T14:30:00 Duration=2-00:00:00\n   Nodes=cn[104-136] NodeCnt=33 CoreCnt=1056 Features=(null) PartitionName=(null) Flags=MAINT,IGNORE_JOBS,SPEC_NODES,ALL_NODES\n   TRES=cpu=2112\n   Users=root Accounts=(null) Licenses=(null) State=INACTIVE BurstBuffer=(null) Watts=n/a\n\nReservationName=maintenance3 StartTime=2024-02-03T14:30:00 EndTime=2024-02-05T14:30:00 Duration=2-00:00:00\n   Nodes=cn[104-136] NodeCnt=33 CoreCnt=1056 Features=(null) PartitionName=(null) Flags=MAINT,IGNORE_JOBS,SPEC_NODES,ALL_NODES\n   TRES=cpu=2112\n   Users=root Accounts=(null) Licenses=(null) State=INACTIVE BurstBuffer=(null) Watts=n/a\n</code></pre>"},{"location":"slurm/#nodes-specs","title":"Node's Specs","text":"<p>Get node's specs.</p> <pre><code>sinfo --Node --responding --long\nsinfo -N -r -l\n</code></pre> NODELIST NODES PARTITION STATE CPUS S:C:T MEMORY TMP_DISK WEIGHT AVAIL_FE REASON cn101 1 TrixieMain* drained 64 2:16:2 192777 0 1 (null) update cn102 1 TrixieMain* mixed 64 2:16:2 192777 0 1 (null) none cn110 1 TrixieMain* mixed 64 2:16:2 192777 0 1 (null) none cn118 1 TrixieMain* idle 64 2:16:2 192777 0 1 (null) none cn119 1 TrixieMain* idle 64 2:16:2 192777 0 1 (null) none cn125 1 TrixieMain* idle 64 2:16:2 192777 0 1 (null) none"},{"location":"slurm/#cluster-usage","title":"Cluster Usage","text":"<p>Find the cluster usage per user.</p> <pre><code>sreport user top start=2020-06-01 end=2020-06-30 -t percent\n</code></pre> <pre><code>--------------------------------------------------------------------------------\nTop 10 Users 2020-06-01T00:00:00 - 2020-06-29T23:59:59 (2505600 secs)\nUsage reported in Percentage of Total\n--------------------------------------------------------------------------------\n  Cluster     Login     Proper Name         Account      Used   Energy\n--------- --------- --------------- --------------- --------- --------\n   trixie  stewartd         Stewart            ai4d    24.23%    0.00%\n   trixie   larkins          Larkin            ai4d    23.75%    0.00%\n   trixie   ryczkok          Ryczko             sdt     3.07%    0.00%\n   trixie      guoh             Guo    ai4d-core-06     0.16%    0.00%\n   trixie       loc              Lo            ai4d     0.13%    0.00%\n   trixie   valdesj          Valdes              dt     0.00%    0.00%\n   trixie       xip              Xi              dt     0.00%    0.00%\n   trixie     asadh                        covid-02     0.00%    0.00%\n   trixie     paulp            Paul            ai4d     0.00%    0.00%\n   trixie    ebadia           Ebadi              dt     0.00%    0.00%\n</code></pre>"},{"location":"slurm/#allocated-hostnames-of-a-multinode-job","title":"Allocated Hostnames of a Multinode Job","text":"<p>Get a list of hostnames allocated to a multi node job.</p> <pre><code>scontrol show hostnames $SLURM_NODELIST\n</code></pre> <pre><code>cn101\ncn102\ncn103\ncn104\n</code></pre>"},{"location":"slurm/#gpsc5","title":"GPSC5","text":""},{"location":"slurm/#ssh-to-a-worker-node","title":"SSH to a Worker Node","text":"<p>This is an example command to connect to a worker node on GPSC5</p> <pre><code>srun --jobid=&lt;JOBID&gt; --overlap --pty bash -l\n</code></pre> <p>Example of connecting to a GPU running job on GPSC5.</p> <pre><code>srun --jobid=&lt;JOBID&gt; --overlap --gres=gpu:8 -N 1 --ntasks=1 --mem-per-cpu=0 --pty -w ib14gpu-001 -s /bin/bash -l\n</code></pre> <pre><code>srun \\\n  --jobid &lt;JOBID&gt; \\\n  --overlap \\\n  --gres=gpu:0 \\\n  --nodes 1 \\\n  --ntasks 1 \\\n  --mem-per-cpu=0 \\\n  --pty \\\n  --nodelist ib12gpu-001 \\\n  --oversubscribe \\\n  /bin/bash -l\n</code></pre>"},{"location":"slurm/#gpscc","title":"GPSCC","text":""},{"location":"slurm/#script-example","title":"Script Example","text":"<p>The following example uses multiple nodes.</p> <pre><code>#!/bin/bash\n\n#SBATCH --job-name=train\n#SBATCH --partition=gpu_a100\n#SBATCH --account=nrc_ict__gpu_a100\n\n#SBATCH --time=2880\n\n##IMPORTANT: `#SBATCH --ntasks-per-node=2`  MUST match  `#SBATCH --gres=gpu:2`\n#SBATCH --nodes=1\n#SBATCH --ntasks-per-node=2\n#SBATCH --gres=gpu:2\n\n#SBATCH --output=%x-%j.out\n#SBATCH --error=%x-%j.err\n#SBATCH --open-mode=append\n#SBATCH --mail-user==tes001\n#SBATCH --mail-type=NONE\n\n#SBATCH --signal=B:15@30\n\n\nulimit -v unlimited\n\ncd /home/tes001/DT/tes001/\nsource ./SETUP_PT2.source\ncd /home/tes001/DT/tes001/LJSpeech-1.1/PT2\n\nsrun everyvoice train text-to-spec --devices 2 --nodes 1 config/everyvoice-text-to-spec.yaml\n</code></pre>"},{"location":"slurm/#sleeper-job","title":"Sleeper Job","text":"<p>Start a sleeper job</p> <pre><code>psub -N sleeper -Q nrc_ict 'sleep 3600'\n</code></pre>"},{"location":"tmux/","title":"<code>tmux</code>","text":""},{"location":"tmux/#exporting-a-variable","title":"Exporting a Variable","text":"<p>tmux is exporting an environment variable that is no longer being exported in .bashrc</p> <pre><code>tmux set-environment -gru FZF_TMUX_OPTS\n</code></pre>"},{"location":"tmux/#rename-a-pane","title":"Rename a pane","text":"<pre><code>set -g pane-border-status top\nset -g pane-border-format \" [ ###P #T ] \"\n</code></pre> <pre><code>CTRL+b + :\nselect-pane -T \"title\"\n</code></pre>"},{"location":"tmux/#sharing-a-window-across-sessions","title":"Sharing a Window Across Sessions","text":"<p>To share a window between two sessions: <code>tmux link-window -s &lt;src-window&gt; -t &lt;dst-window&gt;</code></p>"},{"location":"tmux/#find-a-panes-running-a-command","title":"Find a Panes Running a Command","text":"<p>find-window [-iCNrTZ] [-t target-pane] match-string   (alias: findw)   Search for a fnmatch(3) pattern or, with -r, regular expression match-string   in window names, titles, and visible content (but not history).  The flags   control matching behavior: -C matches only visible window contents, -N matches   only the window name and -T matches only the window title.  -i makes the search   ignore case. The default is -CNT.  -Z zooms the pane.</p> <p>This command works only if at least one client is attached.</p> <pre><code>CTRL+b + f\n&lt;SEARCH STRING&gt;\n</code></pre>"}]}